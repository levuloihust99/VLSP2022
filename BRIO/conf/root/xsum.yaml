# @package _global_
config: xsum

batch_size: 2
epoch: 100
report_freq: 100
accumulate_step: 4
margin: 0.001
gold_margin: 0
gold_weight: 0
mle_weight: 0.1
rank_weight: 10
model_type: google/pegasus-xsum
warmup_steps: 10000
normalize: true
grad_norm: 0
seed: 970903
no_gold: false
pretrained:
max_lr: 2e-3
scale: 0.01
score_mode: log
datatype: diverse
dataset: xsum
max_summ_len: 80
max_candidates: 16
smooth: 0.1
max_doc_len: 512
length_penalty: 0.6
do_generate: true
gen_max_len: 62
gen_min_len: 11
is_pegasus: true
is_t5: false
adding: 0
eval_interval: 1000
num_beams: 8
fp16: false
train_split: train
val_split: val